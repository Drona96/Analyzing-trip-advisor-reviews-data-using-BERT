{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c073f14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import urllib.request\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "77007498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load review data from CSV\n",
    "trip_df = pd.read_excel(\"D:\\TripAdvisor\\TripAdvisor.xlsx\",sheet_name = \"in\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cb1ae2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_Name</th>\n",
       "      <th>Contributions</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date_of_Stay</th>\n",
       "      <th>Heading</th>\n",
       "      <th>Helpulness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13723</th>\n",
       "      <td>David R</td>\n",
       "      <td>Narberth, United States;1 contribution</td>\n",
       "      <td>['Very luxurious']</td>\n",
       "      <td>Beautiful hotel with outstanding service &amp; dra...</td>\n",
       "      <td>Date of stay: June 2015</td>\n",
       "      <td>CONRAD NEW YORK DOWNTOWN - Updated 2023 Prices...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13724</th>\n",
       "      <td>Kate J</td>\n",
       "      <td>London, United Kingdom;7 contributions;11 help...</td>\n",
       "      <td>['Very Impressed - will return']</td>\n",
       "      <td>I booked a standard room quite late in the day...</td>\n",
       "      <td>Date of stay: May 2015</td>\n",
       "      <td>CONRAD NEW YORK DOWNTOWN - Updated 2023 Prices...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13725</th>\n",
       "      <td>travellingangie</td>\n",
       "      <td>Baltimore, Maryland;467 contributions;168 help...</td>\n",
       "      <td>['excellent stay']</td>\n",
       "      <td>this was an excellent hotel, located maybe 4 b...</td>\n",
       "      <td>Date of stay: June 2015</td>\n",
       "      <td>CONRAD NEW YORK DOWNTOWN - Updated 2023 Prices...</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13726</th>\n",
       "      <td>Trend_Dan</td>\n",
       "      <td>Singapore, Singapore;63 contributions;60 helpf...</td>\n",
       "      <td>['A big disappointment']</td>\n",
       "      <td>Having to stay in Conrad Maldives, Tokyo, Seou...</td>\n",
       "      <td>Date of stay: June 2015</td>\n",
       "      <td>CONRAD NEW YORK DOWNTOWN - Updated 2023 Prices...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13727</th>\n",
       "      <td>DiveCaribbean5</td>\n",
       "      <td>Washington, DC;22 contributions;10 helpful votes</td>\n",
       "      <td>['Surprisingly baby friendly hotel']</td>\n",
       "      <td>We've stayed at this hotel a couple of times w...</td>\n",
       "      <td>Date of stay: March 2015</td>\n",
       "      <td>CONRAD NEW YORK DOWNTOWN - Updated 2023 Prices...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             User_Name                                      Contributions  \\\n",
       "13723          David R             Narberth, United States;1 contribution   \n",
       "13724           Kate J  London, United Kingdom;7 contributions;11 help...   \n",
       "13725  travellingangie  Baltimore, Maryland;467 contributions;168 help...   \n",
       "13726        Trend_Dan  Singapore, Singapore;63 contributions;60 helpf...   \n",
       "13727   DiveCaribbean5   Washington, DC;22 contributions;10 helpful votes   \n",
       "\n",
       "                                      Title  \\\n",
       "13723                    ['Very luxurious']   \n",
       "13724      ['Very Impressed - will return']   \n",
       "13725                    ['excellent stay']   \n",
       "13726              ['A big disappointment']   \n",
       "13727  ['Surprisingly baby friendly hotel']   \n",
       "\n",
       "                                                  Review  \\\n",
       "13723  Beautiful hotel with outstanding service & dra...   \n",
       "13724  I booked a standard room quite late in the day...   \n",
       "13725  this was an excellent hotel, located maybe 4 b...   \n",
       "13726  Having to stay in Conrad Maldives, Tokyo, Seou...   \n",
       "13727  We've stayed at this hotel a couple of times w...   \n",
       "\n",
       "                   Date_of_Stay  \\\n",
       "13723   Date of stay: June 2015   \n",
       "13724    Date of stay: May 2015   \n",
       "13725   Date of stay: June 2015   \n",
       "13726   Date of stay: June 2015   \n",
       "13727  Date of stay: March 2015   \n",
       "\n",
       "                                                 Heading  Helpulness  \n",
       "13723  CONRAD NEW YORK DOWNTOWN - Updated 2023 Prices...           0  \n",
       "13724  CONRAD NEW YORK DOWNTOWN - Updated 2023 Prices...          11  \n",
       "13725  CONRAD NEW YORK DOWNTOWN - Updated 2023 Prices...         168  \n",
       "13726  CONRAD NEW YORK DOWNTOWN - Updated 2023 Prices...          60  \n",
       "13727  CONRAD NEW YORK DOWNTOWN - Updated 2023 Prices...          10  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_df['Contributions'].fillna('',inplace = True)\n",
    "trip_df['Helpulness'] = trip_df['Contributions'].apply(lambda x:re.search('(\\d+)(\\s*)helpful', x, re.IGNORECASE))\n",
    "trip_df['Helpulness'] = trip_df['Helpulness'].apply(lambda x:int(x.group(1)) if x is not None else 0)\n",
    "trip_df.tail()\n",
    "# Convert DataFrame to Excel\n",
    "#trip_df.to_excel('trip_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2de37d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating label column\n",
    "trip_df['Label'] = trip_df['Helpulness'].apply(lambda x: 1 if x >= 1 else 0)\n",
    "trip_df.to_excel('trip_bert.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a774a5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_Name</th>\n",
       "      <th>Contributions</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date_of_Stay</th>\n",
       "      <th>Heading</th>\n",
       "      <th>Helpulness</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T5329NXmaryh</td>\n",
       "      <td>Louisville, Kentucky;3 contributions</td>\n",
       "      <td>['Shantel &amp; Luigi welcomed us with smiles and ...</td>\n",
       "      <td>Shantel &amp; Luigi and all front desk staff are e...</td>\n",
       "      <td>Date of stay: June 2023</td>\n",
       "      <td>HILTON GARDEN INN NYC FINANCIAL CENTER / MANHA...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jcmtl1965</td>\n",
       "      <td>Montreal, Canada;8938 contributions;8938;100 h...</td>\n",
       "      <td>['Nice stay for my return to New York']</td>\n",
       "      <td>I hadn't been to New York in 22 months (which ...</td>\n",
       "      <td>Date of stay: August 2021</td>\n",
       "      <td>HILTON GARDEN INN NYC FINANCIAL CENTER / MANHA...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Venture02710567543</td>\n",
       "      <td>1 contribution</td>\n",
       "      <td>['Perfect stay with perfect view']</td>\n",
       "      <td>The convenience of checking in with Nakita Wan...</td>\n",
       "      <td>Date of stay: June 2023</td>\n",
       "      <td>HILTON GARDEN INN NYC FINANCIAL CENTER / MANHA...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leigh H</td>\n",
       "      <td>1 contribution</td>\n",
       "      <td>['Service with a smile']</td>\n",
       "      <td>The front desk staff at our check-in, Nakita, ...</td>\n",
       "      <td>Date of stay: June 2023</td>\n",
       "      <td>HILTON GARDEN INN NYC FINANCIAL CENTER / MANHA...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GrandTour48028656883</td>\n",
       "      <td>1 contribution</td>\n",
       "      <td>['Highly recommend!']</td>\n",
       "      <td>Everyone at this hotel was great! Jaquanna hel...</td>\n",
       "      <td>Date of stay: June 2023</td>\n",
       "      <td>HILTON GARDEN INN NYC FINANCIAL CENTER / MANHA...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              User_Name                                      Contributions  \\\n",
       "0          T5329NXmaryh               Louisville, Kentucky;3 contributions   \n",
       "1             jcmtl1965  Montreal, Canada;8938 contributions;8938;100 h...   \n",
       "2    Venture02710567543                                     1 contribution   \n",
       "3               Leigh H                                     1 contribution   \n",
       "4  GrandTour48028656883                                     1 contribution   \n",
       "\n",
       "                                               Title  \\\n",
       "0  ['Shantel & Luigi welcomed us with smiles and ...   \n",
       "1            ['Nice stay for my return to New York']   \n",
       "2                 ['Perfect stay with perfect view']   \n",
       "3                           ['Service with a smile']   \n",
       "4                              ['Highly recommend!']   \n",
       "\n",
       "                                              Review  \\\n",
       "0  Shantel & Luigi and all front desk staff are e...   \n",
       "1  I hadn't been to New York in 22 months (which ...   \n",
       "2  The convenience of checking in with Nakita Wan...   \n",
       "3  The front desk staff at our check-in, Nakita, ...   \n",
       "4  Everyone at this hotel was great! Jaquanna hel...   \n",
       "\n",
       "                Date_of_Stay  \\\n",
       "0    Date of stay: June 2023   \n",
       "1  Date of stay: August 2021   \n",
       "2    Date of stay: June 2023   \n",
       "3    Date of stay: June 2023   \n",
       "4    Date of stay: June 2023   \n",
       "\n",
       "                                             Heading  Helpulness  Label  \n",
       "0  HILTON GARDEN INN NYC FINANCIAL CENTER / MANHA...           0      0  \n",
       "1  HILTON GARDEN INN NYC FINANCIAL CENTER / MANHA...         100      1  \n",
       "2  HILTON GARDEN INN NYC FINANCIAL CENTER / MANHA...           0      0  \n",
       "3  HILTON GARDEN INN NYC FINANCIAL CENTER / MANHA...           0      0  \n",
       "4  HILTON GARDEN INN NYC FINANCIAL CENTER / MANHA...           0      0  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4bb3d224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "(480, 8)\n",
      "Validation Set:\n",
      "(120, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Assuming you already have the 'trip_df' DataFrame\n",
    "trip_df['Review'] = trip_df['Review'].fillna('')\n",
    "trip_df['Review'] = trip_df['Review'].astype(str)\n",
    "trip_df['Review'] = trip_df['Review'].str.lower()\n",
    "\n",
    "\n",
    "# Select only the first 600 rows from the 'trip_df' DataFrame\n",
    "trip_df_subset = trip_df.iloc[:600, :]\n",
    "\n",
    "\n",
    "# Split the DataFrame into training and validation sets\n",
    "trip_df_train, trip_df_val = train_test_split(trip_df_subset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the resulting DataFrames\n",
    "print(\"Training Set:\")\n",
    "print(trip_df_train.shape)\n",
    "\n",
    "print(\"Validation Set:\")\n",
    "print(trip_df_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "54491f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#import pandas as pd\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "#df = pd.read_excel('/content/data.xlsx')\n",
    "#trip_df['Review'] = trip_df['Review'].fillna('')\n",
    "#trip_df['Review'] = trip_df['Review'].astype(str)\n",
    "#trip_df['Review'] = trip_df['Review'].str.lower()\n",
    "\n",
    "# Split the DataFrame into training and validation sets\n",
    "#trip_df_train, trip_df_val = train_test_split(trip_df, test_size=0.08, random_state=42)\n",
    "\n",
    "# Print the resulting DataFrames\n",
    "#print(\"Training Set:\")\n",
    "#df_train.head()\n",
    "\n",
    "#print(\"Validation Set:\")\n",
    "#trip_df_val.head()\n",
    "#trip_df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "455e4f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.30.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers) (0.16.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2022.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers \n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"distilbert-base-uncased\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "460ae62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask'])\n",
      "dict_items([('input_ids', tensor([[ 101, 1045, 4370,  ...,    0,    0,    0],\n",
      "        [ 101, 2200, 6625,  ...,    0,    0,    0],\n",
      "        [ 101, 3309, 2001,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 2034, 1010,  ...,    0,    0,    0],\n",
      "        [ 101, 1045, 2001,  ...,    0,    0,    0],\n",
      "        [ 101, 2023, 1037,  ...,    0,    0,    0]])), ('attention_mask', tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17600\\4097691673.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tokenized_train = {k:torch.tensor(v).to(device) for k,v in tokenized_train.items()}\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17600\\4097691673.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tokenized_val = {k:torch.tensor(v).to(device) for k,v in tokenized_val.items()}\n"
     ]
    }
   ],
   "source": [
    "tokenized_train = tokenizer(trip_df_train[\"Review\"].values.tolist(), padding = True, truncation = True, return_tensors=\"pt\")\n",
    "tokenized_val = tokenizer(trip_df_val[\"Review\"].values.tolist() , padding = True, truncation = True,  return_tensors=\"pt\")\n",
    "\n",
    "print(tokenized_train.keys())\n",
    "print(tokenized_train.items())\n",
    "#move on device (GPU)\n",
    "tokenized_train = {k:torch.tensor(v).to(device) for k,v in tokenized_train.items()}\n",
    "tokenized_val = {k:torch.tensor(v).to(device) for k,v in tokenized_val.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f7e09a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  hidden_train = model(**tokenized_train) #dim : [batch_size(nr_sentences), tokens, emb_dim]\n",
    "  hidden_val = model(**tokenized_val)\n",
    "\n",
    "#get only the [CLS] hidden states\n",
    "cls_train = hidden_train.last_hidden_state[:,0,:]\n",
    "cls_val = hidden_val.last_hidden_state[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f3a8f284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "60615f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0345, -0.1487,  0.2817,  ...,  0.0992,  0.3654,  0.2890],\n",
      "        [-0.0564, -0.2833,  0.3037,  ..., -0.4367,  0.4253,  0.1608],\n",
      "        [ 0.0373, -0.2357,  0.1162,  ..., -0.3637,  0.5566,  0.0560],\n",
      "        ...,\n",
      "        [-0.0259, -0.0666,  0.1747,  ..., -0.0581,  0.4632,  0.3592],\n",
      "        [ 0.1399, -0.1187,  0.0367,  ...,  0.0041,  0.3943,  0.2891],\n",
      "        [ 0.0226, -0.0072,  0.3378,  ..., -0.1710,  0.6015,  0.2064]])\n",
      "tensor([[ 0.0981, -0.1501,  0.2193,  ..., -0.0686,  0.3885,  0.2730],\n",
      "        [-0.0148,  0.0284,  0.1011,  ...,  0.0191,  0.5658,  0.3365],\n",
      "        [ 0.1234, -0.1156, -0.0148,  ..., -0.0413,  0.2973,  0.1023],\n",
      "        ...,\n",
      "        [ 0.1286,  0.0722,  0.1851,  ..., -0.0448,  0.4759,  0.1226],\n",
      "        [ 0.3463, -0.2160, -0.0551,  ..., -0.0105,  0.5235,  0.4116],\n",
      "        [ 0.0613, -0.1977,  0.0385,  ..., -0.0424,  0.4499,  0.1971]])\n"
     ]
    }
   ],
   "source": [
    "print(cls_train)\n",
    "print(cls_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb00c5ea",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "270d3b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([480, 768]) (480,) torch.Size([120, 768]) (120,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = cls_train.to(\"cpu\")\n",
    "y_train=trip_df_train[\"Label\"]\n",
    "\n",
    "x_val = cls_val.to(\"cpu\")\n",
    "y_val = trip_df_val[\"Label\"]\n",
    "\n",
    "print(x_train.shape,y_train.shape,x_val.shape,y_val.shape)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf=RandomForestClassifier()\n",
    "rf.fit(x_train,y_train)\n",
    "rf.score(x_val,y_val)\n",
    "\n",
    "\n",
    "#cross validation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0c97b105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.71666667 0.75       0.71666667 0.725      0.76666667]\n",
      "Mean Cross-Validation Score: 0.7350000000000001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Combine the training and validation data\n",
    "x_train_val = np.vstack((x_train, x_val))\n",
    "y_train_val = np.concatenate((y_train, y_val))\n",
    "\n",
    "# Create a new RandomForestClassifier instance\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Perform 5-fold cross-validation (you can choose a different number of folds)\n",
    "num_folds = 5\n",
    "scores = cross_val_score(rf, x_train_val, y_train_val, cv=num_folds)\n",
    "\n",
    "# Print the cross-validation scores and the average score\n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "print(\"Mean Cross-Validation Score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2183415f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\admin\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.53.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.3.3)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.12.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (61.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.22.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.22.1)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.7)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.0.4)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.7.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.12.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: transformers in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.30.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers) (0.16.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2022.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f71eed",
   "metadata": {},
   "source": [
    "### Import the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ec3ae115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from transformers import TFDistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0897f98",
   "metadata": {},
   "source": [
    "### Load the pre-trained DistilBERT model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e7586f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "91c4e1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels to numpy arrays if they are not already\n",
    "y_train = y_train.to_numpy()\n",
    "y_val = y_val.to_numpy()\n",
    " # This code converts the labels (target values) y_train and y_val into NumPy arrays. This is done to ensure compatibility with TensorFlow datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "db120234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorFlow Datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(tokenized_train),  # Assuming 'tokenized_train' contains your tokenized data\n",
    "    y_train\n",
    ")).shuffle(len(tokenized_train)).batch(32)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(tokenized_val),  # Assuming 'tokenized_val' contains your tokenized data\n",
    "    y_val\n",
    ")).batch(64)\n",
    "\n",
    "# These lines create TensorFlow datasets for training and validation. It uses the from_tensor_slices method to create a dataset from the tokenized input data (tokenized_train and tokenized_val), paired with their corresponding labels y_train and y_val. \n",
    "# The data is then shuffled for the training dataset using shuffle and batched into batches of size 32 and 64 for training and validation datasets, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14b283b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 248s 16s/step - loss: 0.6160 - accuracy: 0.6875 - val_loss: 0.5897 - val_accuracy: 0.7167\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 254s 17s/step - loss: 0.5881 - accuracy: 0.7083 - val_loss: 0.5808 - val_accuracy: 0.7167\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 246s 17s/step - loss: 0.5392 - accuracy: 0.7083 - val_loss: 0.5464 - val_accuracy: 0.7167\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 249s 17s/step - loss: 0.4655 - accuracy: 0.7375 - val_loss: 0.5358 - val_accuracy: 0.7583\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 232s 15s/step - loss: 0.3897 - accuracy: 0.8333 - val_loss: 0.5523 - val_accuracy: 0.7000\n",
      "2/2 [==============================] - 19s 9s/step - loss: 0.5523 - accuracy: 0.7000\n",
      "Validation Loss: 0.5522689819335938\n",
      "Validation Accuracy: 0.699999988079071\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Compile the model with the optimizer and loss function\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset, epochs=5, validation_data=val_dataset)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_dataset)\n",
    "print(\"Validation Loss:\", loss)\n",
    "print(\"Validation Accuracy:\", accuracy)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
